# Distributed_Data_Analytics_Projects

This repository includes implementations of various machine learning algorithms in distributed programming environments like MPI, Apache Spark, PyTorch, and more. These projects demonstrate the use of distributed systems for data analytics, machine learning, and deep learning.

## Projects

- **Linear Regression with Exact Form & Data Preprocessing**: Linear Regression through exact form using Pandas and Numpy exercises.
  
- **Parallel Matrix Operations with MPI**: Parallel matrix operations such as multiplication, addition, and average calculation using MPI.

- **Text Cleaning & Tokenization with MPI**: Data cleaning, text tokenization, calculation of Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF) on the 20 Newsgroups dataset using MPI.

- **K-Means Clustering on Text Data with MPI**: Implementing the K-Means clustering algorithm on the 20 Newsgroups datasetâ€™s TF-IDF features calculated in Exercise 3 using MPI.

- **Distributed Linear Regression with MPI**: Implementing a supervised machine learning algorithm (Linear Regression) in a distributed setting using MPI (mpi4py). Training with a parallel stochastic gradient descent algorithm.

- **Hadoop Setup & Analysis with MapReduce**: Setting up Hadoop and performing basic Hadoop operations. Analyzing airport efficiency and movie dataset using MapReduce.

- **Image Classification with PyTorch**: Performing network analysis on image classification tasks with PyTorch on the CIFAR-10 and MNIST datasets. Implementing a custom regression task on the MNIST dataset.

- **Advanced Image Classification with PyTorch**: Implementing image classification using PyTorch and analyzing the effects of normalization, dropout, regularization, and data augmentation.

- **Apache Spark Data Operations & Recommender Systems**: Basic operations on dataframes with Apache Spark. Manipulating and analyzing a recommender dataset using Apache Spark.

- **Parallel Stochastic Gradient Descent with PyTorch & MPI**: Implementing Parallel Stochastic Gradient Descent on PyTorch using the MPI framework and parallel processing libraries.

## Requirements

- Python 3.x
- PyTorch
- Apache Spark
- MPI (mpi4py)
- Hadoop
- Other project-specific libraries (see individual project folders for details)

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Distributed_Data_Analytics_Projects.git
